{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sankalp/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-10 11:52:21.983602: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-10 11:52:22.055517: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-10 11:52:22.055561: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-10 11:52:25.631005: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-05-10 11:52:25.631043: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-05-10 11:52:25.631075: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sankalp-HP-Laptop-14s-dq1xxx): /proc/driver/nvidia/version does not exist\n",
      "2024-05-10 11:52:25.631331: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n"
     ]
    }
   ],
   "source": [
    "from gradio import Image, Label, Interface\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# Define input image shape\n",
    "img_shape = (224, 224, 3)\n",
    "\n",
    "# Define your class labels here\n",
    "classes = ['normal', 'smoking', 'spitting']\n",
    "\n",
    "# Load pre-trained DenseNet121 model without the top layer\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=img_shape, pooling='max')\n",
    "\n",
    "# Build your custom classification layers\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n",
    "    Dense(256, kernel_regularizer=tf.keras.regularizers.l2(l=0.016), \n",
    "          activity_regularizer=tf.keras.regularizers.l1(0.006),\n",
    "          bias_regularizer=tf.keras.regularizers.l1(0.006), activation='relu'),\n",
    "    Dropout(rate=0.45, seed=123),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(Adamax(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Load pre-trained weights into the model\n",
    "model.load_weights(\"densenet121-Anomaly-behaviour-denseNet121-weights.h5\")\n",
    "\n",
    "# Define prediction function\n",
    "def predict_image(image_file):\n",
    "    # Resize the input image to match model input shape\n",
    "    img_resized = tf.image.resize(image_file, (img_shape[0], img_shape[1]))\n",
    "    # Make prediction\n",
    "    predictions = model.predict(np.expand_dims(img_resized.numpy(), axis=0))\n",
    "    # Get the predicted class\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    predicted_class = classes[predicted_class_index]\n",
    "    return {classes[i]: float(predictions[0][i]) for i in range(len(classes))}\n",
    "\n",
    "# Interface\n",
    "image_input = Image()  # Allows uploading PIL format images\n",
    "label_output = Label()  # Displays top 3 predictions\n",
    "\n",
    "# Launch the interface\n",
    "Interface(fn=predict_image, inputs=image_input, outputs=label_output).launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/sankalp/.local/lib/python3.10/site-packages/gradio/queueing.py\", line 527, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/sankalp/.local/lib/python3.10/site-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/sankalp/.local/lib/python3.10/site-packages/gradio/blocks.py\", line 1847, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/sankalp/.local/lib/python3.10/site-packages/gradio/blocks.py\", line 1433, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/sankalp/.local/lib/python3.10/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/home/sankalp/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/sankalp/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/sankalp/.local/lib/python3.10/site-packages/gradio/utils.py\", line 805, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_39936/1735985553.py\", line 22, in predict_image\n",
      "    decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
      "  File \"/home/sankalp/.local/lib/python3.10/site-packages/keras/applications/densenet.py\", line 374, in decode_predictions\n",
      "    return imagenet_utils.decode_predictions(preds, top=top)\n",
      "  File \"/home/sankalp/.local/lib/python3.10/site-packages/keras/applications/imagenet_utils.py\", line 147, in decode_predictions\n",
      "    raise ValueError('`decode_predictions` expects '\n",
      "ValueError: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
